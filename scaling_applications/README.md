# 6. Масштабирование приложений

1. Docker registry for Linux Part 1.

<img src="./img/image.png" alt="Docker registry for Linux Part 1" width="500">

3. Docker registry for Linux Parts 2 & 3.

![UNAUTHORIZED](./img/image-1.png)

![Succeeded](./img/image-2.png)

3. Изучите материал «Docker Orchestration Hands-on Lab».


| Фото |
|------|
|![1](./img/image-3.png)|
|![2](./img/image-4.png)|
|![3](./img/image-5.png)|
|![4](./img/image-6.png)|
|![5](./img/image-7.png)|
|![6](./img/image-8.png)|

- Восстановилась ли работа запущенного сервиса на этом узле? Нет. После перевода узла из состояния Drain обратно в Active Docker Swarm не переносит задачи сервиса обратно автоматически.

- Что необходимо сделать, чтобы снова запустить сервис на этом узле? Нужно инициировать перераспределение задач сервиса, или изменить количество реплик.

4. Изучите материал «Swarm stack introduction».

| Фото |
|------|
|![1](./img/image-9.png)|
|![2](./img/image-10.png)|
|![3](./img/image-11.png)|

- Как конфигурируется количество нодов в стэке? Количество экземпляров сервисов в Docker Swarm-стэке задаётся в файле docker-stack.yml с помощью параметра deploy.replicas. Параметр определяет число реплик сервиса, которые планировщик Swarm автоматически распределяет по узлам кластера.

- Как организуется проверка жизнеспособности сервисов? Контроль работоспособности осуществляется средствами Docker Swarm, который отслеживает состояние задач и автоматически перезапускает контейнеры в случае их отказа, поддерживая заданное количество реплик сервисов.

Docker Swarm поддерживает механизм healthcheck, который может быть описан в docker-stack.yml, например:
```bash
healthcheck:
  test: ["CMD", "curl", "-f", "http://localhost"]
  interval: 30s
  timeout: 10s
  retries: 3
```

**Оценка производительности Flask-приложения при масштабировании в Docker Swarm**

| Фото |
|------|
|![1](./img/image-12.png)|
|![2](./img/image-13.png)|
|![3](./img/image-14.png)|

Конфигурация теста:

- Инструмент: wrk
- 4 потока, 50 соединений
- Длительность: 30 секунд
- Endpoint: GET /api/counter

| Параметр    | 1 реплика | 4 реплики | Изменение |
| ----------- | --------- | --------- | --------- |
| RPS         | 1695      | 2203      | **+30%**  |
| Avg Latency | 10.61 ms  | 8.65 ms   | **−18%**  |

- Изменился ли потенциал при обработке запросов? Да, изменился. При увеличении количества инстансов Flask с 1 до 4 – пропускная способность выросла примерно на 30%, а средняя задержка уменьшилась. Это означает, что приложение выигрывает от кластеризованного развертывания, даже в условиях одного хоста.

- Существуют ли какие-то особенности при работе реплицированного сервиса с БД? Репликация сервиса базы данных без поддержки кластеризации приводит к нарушению целостности данных. В отличие от stateless-сервисов, базы данных требуют специализированных механизмов синхронизации состояния.


**Оценка производительности Flask-приложения при масштабировании в k8s**

| Фото |
|------|
|![1](./img/image-15.png)|
|![2](./img/image-16.png)|
|![3](./img/image-17.png)|
|![4](./img/image-18.png)|

Конфигурация теста

- Инструмент: wrk
- Потоки: 4
- Соединения: 50
- Длительность: 30 секунд
- Endpoint: GET /api/counter

| Параметр     | 1 реплика | 4 реплики | Изменение       |
| ------------ | --------- | --------- | --------------- |
| Requests/sec | 1309.72   | 1812.60   | **+38%**        |
| Avg Latency  | 14.10 ms  | 14.11 ms  | без изменений |

- Изменился ли потенциал обработки запросов? Увеличение количества реплик Flask-сервиса с 1 до 4 привело к росту пропускной способности примерно на 38%. Средняя задержка осталась практически неизменной.

- Сравнение с Docker Swarm. Эффект масштабирования в Kubernetes сопоставим с Docker Swarm, однако более сложная сетевая модель Kubernetes приводит к дополнительным накладным расходам и снижению RPS.
