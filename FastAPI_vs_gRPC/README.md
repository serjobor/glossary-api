# 5. Сравнение производительности приложений на FastAPI. REST и gRPC

## 1. Методология тестирования

Разработаны два сервиса для управления словарём терминов (без использования БД, данные в памяти):
- **REST-сервис** на FastAPI.
- **gRPC-сервис** с использованием Protocol Buffers.

В каждом реализованы три операции: `GET`, `POST`, `PUT`.

### Нагрузочное тестирование
Проведено с помощью **Locust**.

**Поведение виртуальных пользователей:** Последовательное выполнение операций с паузой 1-3 секунды. Распределение запросов: 60% `GET`, 30% `POST`, 10% `PUT`.

**Сценарии нагрузки:**

| Сценарий | Макс. пользователей | Пользователи в сек | Длительность, сек |
|--------------------------------|------|---|-----|
| Лёгкая нагрузка (Sanity Check) | 10   | 2 | 30  |
| Рабочая нагрузка               | 100  | 5 | 60  |
| Стресс-тест (пиковая)          | 1000 | 5 | 120 |
| Тест на стабильность           | 30   | 5 | 300 |           

## 2. Инструкция по запуску

### Общие шаги
```bash
# Создание виртуального окружения
python -m venv venv

# Активация (Windows)
venv\Scripts\activate

# Установка зависимостей
pip install -r requirements.txt
```

### Запуск REST-сервиса
```bash
# Запуск сервера
uvicorn rest.app:app

# В отдельном терминале - запуск тестов
python -m locust -f locust-tests/rest_client.py --host=http://127.0.0.1:8000
```

### Запуск gRPC-сервиса
```bash
# Генерация кода из .proto файла
python -m grpc_tools.protoc -Igrpc/protobufs --python_out=grpc --grpc_python_out=grpc grpc/protobufs/glossary.proto

# Запуск сервера
python grpc/server.py

# В отдельном терминале - запуск тестов
python -m locust -f locust-tests/grpc_client.py --host=http://127.0.0.1:50051
```

**Веб-интерфейс Locust** доступен по адресу: `http://localhost:8089`

## 3. Тестовая среда

| Параметр | Значение |
|----------|----------|
| Модель устройства | Acer Aspire 15 A15-41M-R309 |
| Процессор | AMD Ryzen 5 7535U (6 ядер/12 потоков) |
| Тактовая частота | 2.9 ГГц |
| Видеокарта | AMD Radeon 660M |
| Оперативная память | 16GB DDR5, 3200 МГц |
| Операционная система | Windows 10 Pro 22H2 |
| Браузер тестирования | Google Chrome 143.0.7499.170 |

## 4. Результаты тестирования

### REST-сервис
| Тест | Метрики | Графики |
|------|---------|---------|
| 1. Лёгкая нагрузка | ![](./img/rest-t1.png) | ![](./img/rest-t1-g1.png) |
| 2. Рабочая нагрузка | ![](./img/rest-t2.png) | ![](./img/rest-t2-g2.png) |
| 3. Стресс-тест | ![](./img/rest-t3.png) | ![](./img/rest-t3-g3.png) |
| 4. Стабильность | ![](./img/rest-t4.png) | ![](./img/rest-t4-g4.png) |

### gRPC-сервис
| Тест | Метрики | Графики |
|------|---------|---------|
| 1. Лёгкая нагрузка | ![](./img/grpc-t1.png) | ![](./img/grpc-t1-g1.png) |
| 2. Рабочая нагрузка | ![](./img/grpc-t2.png) | ![](./img/grpc-t2-g2.png) |
| 3. Стресс-тест | ![](./img/grpc-t3.png) | ![](./img/grpc-t3-g3.png) |
| 4. Стабильность | ![](./img/grpc-t4.png) | ![](./img/grpc-t4-g4.png) |

## 5. Ключевые выводы

### 5.1. Устойчивость к нагрузке
Сервис на **gRPC** продемонстрировал значительно более высокую устойчивость:
- Деградация производительности **REST-сервиса** началась при ~500 одновременных пользователей
- **gRPC** не показал серьёзных проблем на этой нагрузке

### 5.2. Производительность
- **gRPC** показал более высокие и стабильные значения RPS (запросов в секунду)
- Лучшая латентность у gRPC, особенно на высоких перцентилях под пиковой нагрузкой
- При низкой и умеренной нагрузке значения RPS сравнимы

### 5.3. Архитектурные наблюдения
- Отсутствие механизма удаления данных и хранение всего набора в памяти могут привести к утечкам памяти при длительной работе
- **Рекомендация:** добавить пагинацию для `GET`-запросов

## 6. Сравнение REST и gRPC

| Критерий | REST (FastAPI) | gRPC |
|----------|---------------|------|
| Простота реализации | Высокая | Средняя/Низкая (требует .proto) |
| Скорость отладки | Высокая | Средняя |
| Производительность | Умеренная | Высокая |
| Потребление памяти | Выше | Ниже |
| Устойчивость к нагрузке | До ~500 пользователей | Выше 500 пользователей |
| Overhead передачи | JSON (больше) | Protobuf (меньше) |

### Рекомендации по применению:

**Выбирать REST (FastAPI) когда:**
- Не требуются экстремальные нагрузки
- Важна скорость разработки и отладки
- Нужна простота интеграции с фронтендом

**Выбирать gRPC когда:**
- Микросервисная архитектура
- Внутренняя коммуникация сервисов
- Высокие требования к производительности
- Эффективная работа под высокой нагрузкой

## 7. Ограничения и рекомендации

### Ограничения эксперимента:
1. Все компоненты запускались на одной машине (исключены сетевые задержки)
2. Искусственный характер нагрузки
3. Отсутствие реальной базы данных и внешних зависимостей
4. Тестирование только в локальной среде

### Возможные улучшения:
1. **Интеграция с БД:** Добавить PostgreSQL/Redis для реалистичного тестирования
2. **Распределённое тестирование:** Запуск в облачной среде с учётом сетевых факторов
3. **Разнообразие аппаратного обеспечения:** Тесты на разных конфигурациях
4. **Расширение сценариев:** Добавить операции DELETE, сложные запросы
5. **Мониторинг ресурсов:** Детальное отслеживание CPU, памяти, сети

## 8. Заключение

1. **Основной вывод:** gRPC показал себя более стабильным и производительным решением под высокой нагрузкой, однако требует более сложной реализации и настройки.

2. **Оптимизация:** Для промышленного использования обоих сервисов необходимо:
   - Внедрить пагинацию
   - Добавить механизм очистки старых данных
   - Рассмотреть кэширование

3. **Баланс:** Выбор между REST и gRPC должен основываться на конкретных требованиях проекта: времени разработки, ожидаемой нагрузке и сложности интеграции.


### Задание

Сравнить с помощью Locust приложения с глоссарием на предмет производительности их работы

Освоить методы проведения нагрузочного тестирования сетевых сервисов (REST и gRPC), научиться использовать инструмент Locust для генерации нагрузки, анализа поведения приложения под разными профилями нагрузки и формализации результатов.

1. **Развернуть приложения, разработанные в рамках предыдущих заданий (словарь терминов):**
FastAPI с использованием REST-подхода. 
приложение-словарь с использованием подхода RPC и передачи данных по протоколу protobuf. 

2. **Приложение должно содержать минимум 2 разных эндпоинта/метода, отличающихся логикой или трудоёмкостью.**
**Настроить нагрузочное тестирование с помощью Locust:**
Написать один или два класса пользователей (User/GrpcUser) в зависимости от тестируемых протоколов.
Смоделировать реалистичное поведение клиентов: разные сценарии запросов, пропорции между ними, паузы, последовательности действий.
Настроить параметры запуска Locust: количества пользователей, скорость подъёма нагрузки, длительность теста.

3. **Провести тестирование по нескольким сценариям нагрузки:**
- Лёгкая нагрузка (sanity check): убедиться, что всё работает.
- Рабочая нагрузка (нормальный режим): подобрать параметры, имитирующие реалистичное использование.
- Стресс-тест (приближение к пику): выявить пределы производительности.
- Тест на стабильность (при длительной нагрузке): проверить деградацию.
- Зафиксировать метрики:

- RPS (запросов в секунду),
- среднее время ответа,
- распределение латентности (p95/p99),
- количество ошибок,
- момент наступления деградации,
- влияние увеличения числа пользователей.
- Сравнить результаты REST и gRPC:

- обнаружить различия в пропускной способности и задержках,
- оценить влияние размера сообщений, сериализации, network-overhead.
- Требования к отчёту
- Отчет разместить в репозитории, отразите отчет с помощью файла с разметкой Markdown, где демонстрировался бы процесс развертывания и работы сервиса.

Опишите тестируемое приложения (архитектура, используемые технологии, использовалась ли БД, какие данные возвращаются, какие данные необходимы для выполнения запроса на добавление).

1. **Укажите настройки тестовой среды**
- аппаратные ресурсы (CPU, RAM, сеть),
- архитектуру стенда (что где запущено),
- версию Locust,
- дополнительные инструменты мониторинга (если использовались).

2. **Тестовые сценарии**
**Для каждого сценария описать:**
- логика поведения пользователя (task flow),
- конфигурация нагрузки (пользователи, spawn rate, длительность),
- ожидания перед запуском (гипотезы).
- Приложить фрагменты тестового кода Locust.

3. **Результаты тестирования**

**Для каждого сценария включить:**

3.1. **Основные метрики:** 
- RPS / Throughput,
- среднее время ответа,
- p95/p99 latency,
- количество ошибок (5xx/timeout/connection errors),
- графики или таблицы (можно экспорт Locust или собственные визуализации).

3.2. **Анализ результатов:** 
- На каком количестве пользователей начинается деградация?
- Как изменяется латентность при росте нагрузки?
- Где «бутылочное горлышко» — CPU, база данных, сеть, сама реализация сервиса?
- Отличаются ли результаты REST и gRPC?

4. **Сравнить REST и gRPC**
- численное сравнение латентности,
- сравнение RPS,
- анализ overhead,
- выводы о применимости каждого подхода.

**В заключении обязательно включить:**
- основные выводы,
- рекомендации по оптимизации,
- возможные улучшения эксперимента,
- ограничения проведённого тестирования.

**Исследовательская задача**
- Составьте подборку статей, где проводилось бы сравнение реализаций микросервисной архитектуры с помощью подходов REST и RPC, 
- GraphQL. 

Приоритет — исследования, где выполнялись бы замеры и бенчмарки. Приведите наиболее важные результаты таких исследований. Составьте краткое резюме этих исследований. 